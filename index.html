<!doctype html>
<meta charset="utf-8">
<script src="https://distill.pub/template.v1.js"></script>

<script type="text/front-matter">
  title: "Morphognostic honey bees communicating nectar location through dance movements"
  description:
  authors:
  - Thomas E. Portegys: http://tom.portegys.com/research.html#honey_bees
  affiliations:
  - Dialectek: http://dialectek.com
</script>

<dt-article>
  <h1>Morphognostic honey bees communicating nectar location through dance movements</h1>
  <h2>Honey bees are social insects that forage for flower nectar cooperatively. When an individual
  forager discovers a flower patch rich in nectar, it returns to the hive and performs a "dance" in
  the vicinity of other bees that consists of movements communicating the direction and distance to 
  the nectar source. The bees that receive this information then fly to the location of the nectar to 
  retrieve it, thus cooperatively exploiting the environment. This project simulates this behavior in 
  a cellular automaton using the Morphognosis model. The model features hierarchical spatial and temporal 
  contexts that output motor responses from sensory inputs. Given a set of bee foraging and dancing 
  exemplars, and exposing only the external input-output of these behaviors to the Morphognosis learning 
  algorithm, a hive of artificial bees can be generated that forage as their biological counterparts do.
  <p>
  <h3>Keywords: Honey bee foraging dance, artificial animal intelligence, Morphognosis, cellular automaton, artificial neural network.</h3></h2>
  <dt-byline></dt-byline>
  <h2>Introduction</h2>
  <p>Honey bees, <i>apis mellifera</i>, are fascinating social insects. They are also smart, even able to count and add <dt-cite key="fox2019"></dt-cite>.
  However, it is their ability to communicate symbolically in the form of a "dance" indicating the direction and distance
  to a nectar source that is truly astonishing <dt-cite key="chittka2018"></dt-cite><dt-cite key="nosowitz2016"></dt-cite><dt-cite key="schurch2019"></dt-cite><dt-cite key="vonfrisch1967"></dt-cite>,
  especially considering that the use of symbols is rare even in more neurologically complex animals. The dance, done
  by a bee in the presence of other bees in the hive after discovering nectar at a locale outside the hive, recruits
  bees to forage at the indicated location, thus acquiring more nectar than solitary foraging would otherwise.</p>
  <p>This paper describes artificial honey bees that gather nectar and perform the foraging dance. It employs a general machine 
  learning system, <i>Morphognosis</i>, which acquires behaviors by example and enables an artificial organism to express those behaviors.
  It will be shown that simulating nectar foraging is a difficult task for unaugmented machine learning methods, but with the support 
  of the spatial and temporal contextual information that Morphognosis provides, it can be accomplished.</p>
  <p>As a disclaimer, it should be noted that this project is not intended to offer new or additional findings about honey bees. Its goal 
  is to simulate a biologically inspired behavior in a dynamic environment. If the convergence of nature and artifice at the behavioral
  level provides insights about biological mechanisms, that would be serendipitous.</p>
  <p>Honey bees have been the focus and inspiration for a number of simulation initiatives:</p>
  <ul>
  <li style="margin-bottom:0px;">Detailed colony behavior <dt-cite key="betti2017"></dt-cite>.</li>
  <li style="margin-bottom:0px;">Swarming and group behavior algorithms <dt-cite key="karaboga2009"></dt-cite>.</li>
  <li style="margin-bottom:0px;">Flight neural network <dt-cite key="cope2013"></dt-cite>.</li>
  <li style="margin-bottom:0px;">Visual system neural network <dt-cite key="roper2017"></dt-cite>.</li>
  <li style="margin-bottom:0px;">Odor learning circuits <dt-cite key="maboudi2017"></dt-cite>.</li>
  <li style="margin-bottom:0px;">Spiking neural network that reacts to nectar <dt-cite key="fernando2015"></dt-cite>.</li>
  </ul>
  <p>The colony simulation allows a user to observe how bees are affected by various environmental conditions, such as weather. 
  Algorithms for a number of group behaviors, optimal foraging strategies among them, are cited in the swarming paper.
  The other projects simulate bee-specific neural mechanisms. For example, the odor learning project found that simulated honey 
  bees lacking mushroom bodies, the insect equivalent of the cerebral cortex, may still be able to learn odors. The spiking 
  neural network measures how an abstracted model of a bee's nervous system reacts to nectar-related stimuli.</p>
  <p>In contrast, the contribution of this project is to simulate honey bee behavior with a general purpose connectionist model 
  that learns from external observations and which is applicable to arbitrary behavioral simulation tasks, not just the honey 
  bee foraging task.</p>
  <p>A number of years ago I explained to a coworker how my dissertation program <dt-cite key="portegys1986"></dt-cite>, a model of instrumental/operant
  conditioning, could learn various tasks through reinforcement. He then asked me how "smart" it was. I put him off, not having
  a ready answer. He persisted. So I blurted out that it was as smart as a cockroach (which it is not). To which he replied,
  "Don't we have enough real cockroaches?" Fast forward to this project. Don't we have enough real honey bees? (Maybe we don't <dt-cite key="oldroyd2007"></dt-cite>!)</p>
  <p>The point of this story is that the question of why anyone should work on artificial animal intelligence is, at least on the surface, 
  a reasonable one, given our species unique intellectual accomplishments. Thus, historically, AI has mostly focused on human-like 
  intelligence, for which there are now innumerable success stories: games, self-driving cars, stock market forecasting, medical 
  diagnostics, language translation, image recognition, etc. Yet the elusive goal of artificial general intelligence (AGI) seems as 
  far off as ever. This is because these success stories lack the
  "general" property of AGI, operating as they do within narrow, albeit deep, domains. A language translation application, for 
  example, does just that and nothing else.</p>
  <p>Anthony Zador <dt-cite key="zador2019"></dt-cite> expresses this succinctly: "We cannot build a machine capable of building a nest, or stalking prey, or
  loading a dishwasher. In many ways, AI is far from achieving the intelligence of a dog or a mouse, or even of a spider, and it does 
  not appear that merely scaling up current approaches will achieve these goals."</p>
  <p>I am in the camp that believes that achieving general animal intelligence is a necessary, if not sufficient, path to AGI. While 
  imbuing machines with abstract thought is a worthy goal, in humans there is a massive amount of ancient neurology that underlies 
  this talent.</p>
  <p>Hans Moravec put it thusly <dt-cite key="moravec1988"></dt-cite>: "Encoded in the large, highly evolved sensory and motor portions of the human brain is a billion
  years of experience about the nature of the world and how to survive in it. The deliberate process we call reasoning is, I believe, 
  the thinnest veneer of human thought, effective only because it is supported by this much older and much more powerful, though usually 
  unconscious, sensorimotor knowledge. We are all prodigious Olympians in perceptual and motor areas, so good that we make the difficult 
  look easy. Abstract thought, though, is a new trick, perhaps less than 100 thousand years old. We have not yet mastered it. It is not 
  all that intrinsically difficult; it just seems so when we do it."</p>
  <p>So how should we proceed? Emulating organisms at the level of neurons (whole-brain emulation) is a possible approach to understanding 
  animal intelligence. However, efforts to do this with the human brain have met with little success <dt-cite key="yong2019"></dt-cite>. Scaling down to mice is
  an option. The human brain dwarfs the mouse brain, but even mouse brains are daunting: a cubic milliliter of mouse cortex contains 
  900,000 neurons and 700,000,000 synapses <dt-cite key="braitenberg1998"></dt-cite>. At much a simpler scale, years have been spent studying the 
  relationship between the connectome of the nematode C. elegans <dt-cite key="wood1988"></dt-cite>, with only 302 neurons, and its behaviors, but even this
  creature continues to surprise and elude full definition. Nevertheless, some researchers believe that it is now feasible for the 
  whole-brain approach to be applied to insects such as the fruit fly, with its 135,000 neurons <dt-cite key="collins2019"></dt-cite>. Partial brain analysis
  is also an option. For example, the navigation skills of honey bees are of value to drone technology. Fortunately, it appears that 
  the modular nature of the honey bee brain can be leveraged to replicate this skill <dt-cite key="nott2018"></dt-cite>.</p>
  <p>Another issue with emulation is the difficulty of mapping the relationship between neural structures and behaviors <dt-cite key="krakauer2016"></dt-cite> <dt-cite key="yong2017"></dt-cite>.
  For AI, this is a key aspect, as behavior is the goal. Nature is a blind tinkerer.
  For example, despite the enthusiasm following the mapping of the human genome, the mechanisms by which genes express proteins, 
  and thus phenotypes, is not as modular as hoped for. Rather, it is extraordinarily complex <dt-cite key="wade2001"></dt-cite>. 
  In artificial systems, artifacts and quirks left over by evolution can introduce unnecessary complexity.</p>
  <p>The field of artificial life (Alife) offers another path to AGI. This path starts with simulating life, and letting evolution
  optimize artificial organisms to achieve intelligence as a fitness criteria. For example, Sch&ouml;neburg's <dt-cite key="schoneburg2019"></dt-cite> "alternative path to AGI", sees
  intelligence emerging from <i>holobionts</i>, which form cooperating collectives of artificial agents.</p>
  <p>Morphognosis carries on the trend set by artificial neural networks to abstractly model neurological computing functions.
  However, the approach is primarily to simulate at the behavioral level. Considering the vastly different "clay" that biological and
  computing systems are built with, cells vs. transistors and software, behavioral simulation seems a good place to converge. 
  I believe the famous Turing Test <dt-cite key="turing1950"></dt-cite> follows this line of thought.</p>
  <p>Morphognosis comprises an artificial neural network (ANN) enhanced with a framework for organizing sensory events into hierarchical 
  spatial and temporal contexts. Nature has hard-wired knowledge of space and time into the brain as way for it to effectively interact 
  with the environment <dt-cite key="bellmund2018"></dt-cite> <dt-cite key="hainmuller2018"></dt-cite> <dt-cite key="lieff2015"></dt-cite> <dt-cite key="vorhees2014"></dt-cite>. These capabilities
  are modeled by Morphognosis. Interestingly, grid cells also appear in humans to be capable of representing not only spatial relationships,
  but non-spatial multidimensional ones, such as the relationships between members of a group of people <dt-cite key="bruner2018"></dt-cite> <dt-cite key="tavares2015"></dt-cite>.</p>
  <p>The bee dancing behavior, as a sequential process, has temporal components. For example a bee must remember a past event, the existence 
  of surplus nectar in a flower, and use that information to perform a dance that indicates both direction and distance to the nectar. 
  In addition, bees that observe a dance must internally persist the distance signal and use it to measure how far to fly.</p>
  <p>Sequential processes are type of task that recurrent artificial neural networks (RNNs) have been successfully applied 
  to <dt-cite key="elman1990"></dt-cite> <dt-cite key="hochreiter1997"></dt-cite>. However, RNNs do not inherently also support spatial information. RNNs
  maintain internal feedback that allow them to retain state information within the network over time. This contrasts with Morphognosis, 
  where the input itself contains temporal state information.</p>
  <p>Morphognosis was partly inspired by some what-if speculation. In simpler animals, the "old" brain (amygdala, hypothalamus, hippocampus,
  etc.) deals more directly with an unfiltered here-and-now version of the environment. Considering nature's penchant for repurposing
  existing capabilities, might it be that in more complex animals a purpose of the neocortex, sitting atop the old brain and filtering 
  incoming sensory information, is to track events from distant reaches of space and time and render them, as though near and present, to
  the old brain whose primal functions have changed little over time?</p>
  <p>I have previously conducted research explorations into a number of issues that differentiate conventional AI from natural
  intelligence. These include context, motivation, plasticity, modularity, instinct, and surprise <dt-cite key="portegys2007"></dt-cite> <dt-cite key="portegys2010"></dt-cite> <dt-cite key="portegys2013"></dt-cite> <dt-cite key="portegys2015"></dt-cite>.
  Morphognosis, in particular, has been previously applied to the task of nest-building by a species of pufferfish <dt-cite key="portegys2019"></dt-cite>.</p>
  <p>To date, including the honey bee project, Morphognosis has been implemented as a cellular 
  automaton <dt-cite key="toffoli1987"></dt-cite> <dt-cite key="wolfram2002"></dt-cite>, as the rules that it develops while learning are ideally captured in a grid
  structure. Conceptually, however, Morphognosis is not tied to the cellular automaton scheme.</p>
  <p>The next section describes Morphognosis and details of the behavior and implementation of the honey bees. A section with the results 
  of testing pertinent variables follows. A subsection also presents by way of comparison the performance of a recurrent neural network 
  (see LSTM performance).</p>
  <h2>Description</h2>
  <p>This section first briefly describes the Morphognosis model. The honey bee behavior and implementation are described next.</p>
  <h3>Morphognosis overview</h3>
  <p><i>Morphognosis</i> (<i>morpho</i> = shape and <i>gnosis</i> = knowledge) aims to be a general method of capturing contextual information 
  that can enhance the power of an artificial neural network (ANN). It provides a framework for organizing spatial and temporal sensory 
  events and motor responses into a tractable format suitable for ANN training and usage.</p>
  <p>Introduced with several prototype tasks <dt-cite key="portegys2017b"></dt-cite>, Morphognosis has also modeled the locomotion and foraging of the
  C. elegans nematode worm <dt-cite key="portegys2018"></dt-cite> and the nest-building behavior of a pufferfish <dt-cite key="portegys2019"></dt-cite>. Morphognosis is a temporal
  extension of a spatial model of morphogenesis <dt-cite key="portegys2017a"></dt-cite>.</p>
  <h4 style="font-size: 18px;">Morphognostics</h4>
  <p>The basic structure of Morphognosis is a cone of sensory event recordings called a <i>morphognostic</i>, shown in Figure 1. At the apex of
  the cone are the most recent and nearby events. Receding from the apex are less recent and possibly more distant events. A morphognostic 
  can thus be viewed as a structure of progressively larger nested chunks of space-time knowledge that form a hierarchy of contexts. A set 
  of morphognostics forms long-term memories that are learned by exposure to the environment. Scaling can be accomplished by aggregating 
  event information. This means that more recent and nearby events are recorded in greater precision than events more distant in space and time.</p>
  <img src="images/figure1.png" style="position:relative; left:190px;" />
  <p style="position:relative; left:160px;">Figure 1 - Morphognostic event cone.</p>
  <p>The following are possible definitions of the spatial and temporal morphognostic neighborhoods. The software is parameterized to 
  permit many variations of these definitions.</p>
  <p><b><i>Morphognostic spatial neighborhoods</b></i></p>
  <p>A cell defines an elementary neighborhood:</p>
  <img src="images/equation1.png" style="position:relative; left:190px;" />
  <p>A non-elementary neighborhood consists of an <i>NxN</i> set of sectors surrounding a lower level neighborhood:</p>
  <img src="images/equation2.png" style="position:relative; left:190px;" />
  <p>Where <i>N</i> is an odd positive number.
  <p>The value of a sector is a vector representing a histogram of the cell type densities contained within it:</p>
  <img src="images/equation3.png" style="position:relative; left:190px;" />
  <p><b><i>Morphognostic temporal neighborhoods</b></i></p>
  <p>A neighborhood contains events that occur within a duration, which is a time window between the present and some time in the past.
  Here is a possible method for calculating the duration of each neighborhood algorithmically:</p>
  <img src="images/algorithm1.png" style="position:relative; left:190px;" />
  <p><b><i>Morphognostic example</b></i></p>
  <p>Figure 2 is an example of a morphognostic implemented in a cellular automaton as a nested set of 3x3 neighborhoods and 
  aggregated histograms of cell state value densities. On the left is the cellular automata grid that contains various cell state 
  values. Moving right is a 3x3 neighborhood surrounding one of the cells of interest. This neighborhood is sensed in the immediate 
  present. Moving right to the 9x9 neighborhood, each sector is a 3x3 neighborhood aggregated in space and time. Thus the densities 
  are variable. The rightmost panel continues this theme to a 27x27 neighborhood.</p>
  <img src="images/figure2.png" style="position:relative; left:190px;" />
  <p style="position:relative; left:50px;">Figure 2 - Cellular automaton implementation of Morphognosis.</p>
  <h4 style="font-size: 18px;">Metamorphs</h4>
  <p>In order to navigate and manipulate the environment, it is necessary for an agent to be able to respond to the environment. 
  A <i>metamorph</i> embodies a morphognostic?response rule. A set of metamorphs can be learned from a manual or programmed sequence of
  responses within a world.</p>
  <p>Metamorphs are used to train an ANN, as shown in Figure 3, to learn responses associated with morphognostic inputs. During 
  operation, the current morphognostic, representing the state of the environment, is input to the ANN to produce a learned response.</p>
  <img src="images/figure3.png" style="position:relative; left:190px;" />
  <p style="position:relative; left:90px;">Figure 3 - Metamorph artificial neural network.</p>
  <h3>Honey bees</h3>
  <h4 style="font-size: 18px;">Behavior</h4>
  <p>A brief explanatory video:</p>
  <iframe style="position:relative; left:190px;" width="560" height="315" src="https://www.youtube.com/embed/kUAv2QO7qYM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  <p><b><i>Sensory and response capabilities</b></i></p>
  <p style="margin-bottom:0px;">Senses:</p>
  <p style="margin-bottom:0px;"><i>External state:</i></p>
  <ul>
  <li style="margin-bottom:0px;">Hive presence.</li>
  <li style="margin-bottom:0px;">Nectar presence.</li>
  <li style="margin-bottom:0px;">In-hive bee nectar signal: Orientation and distance to nectar.</li>
  </ul>
  <p style="margin-bottom:0px;"><i>Internal state:</i></p>
  <ul>
  <li style="margin-bottom:0px;">Orientation.</li>
  <li style="margin-bottom:0px;">Carrying nectar.</li>
  </ul>
  <p style="margin-bottom:0px;">Responses:</p>
  <ul>
  <li style="margin-bottom:0px;">Wait.</li>
  <li style="margin-bottom:0px;">Move forward.</li>
  <li style="margin-bottom:0px;">Turn in compass directions: N, NE, E, SE, S, SW, W, NW.</li>
  <li style="margin-bottom:0px;">Extract nectar.</li>
  <li style="margin-bottom:0px;">Deposit nectar.</li>
  <li style="margin-bottom:0px;">Display nectar distance.</li>
  </ul>
  <p><b><i>World</b></i></p>
  <p>Figure 4 shows a graphical view that shows a hive (central yellow area), three bees, and three flowers. 
  The topmost flower contains a drop of nectar to which the topmost bee, as best it can in a cellular grid, is 
  indicating the direction and an approximate distance to, as indicated by the orientation of the bee and the 
  length of the dotted line, respectively. The world is bounded by its edges, meaning bees cannot leave one edge 
  and appear on the opposite side. An attempt to move beyond the edge results in a forced random change of direction.</p>
  <img src="images/figure4.png" style="position:relative; left:220px;" />
  <p style="position:relative; left:120px;">Figure 4 - Graphical view.</p>
  <p><b><i>Bees</b></i></p>
  <p>A bee occupies a single cell and is oriented in one of the eight compass directions and moves in the direction of its 
  orientation. Only one bee is allowed per cell. An attempt to move to an occupied cell is disallowed. If multiple bees 
  move to the same empty cell, a random decision is made to allow one bee to move. Bees can carry a single unit of nectar. 
  Bees are initialized in the hive at random positions and orientations.</p>
  <p><b><i>Flowers</b></i></p>
  <p>A flower occupies a single cell outside of the hive at a random location. A flower's cell may also be occupied by a 
  single visiting bee. Flowers are initialized with nectar, which after being extracted by a bee, will probabilistically 
  either replenish after a specific time or immediately replenish. In the latter case, the bee will sense the presence of 
  surplus nectar and will perform a dance to indicate its direction and distance once it returns to the hive. Flowers are 
  initialized at random locations.</p>
  <p><b><i>Foraging</b></i></p>
  <p>The bees forage in two phases. In phase one, the nectar discovery phase, a bee flies about semi-randomly until it 
  encounters a flower with nectar. Phase two is a deterministic process that deals with known nectar. Phase two is described below.</p>
  <p>Once discovered, the bee extracts the nectar from the flower, flies directly to the hive and deposits the nectar in the hive. 
  If the bee, after depositing the nectar, remembers that the flower contained "surplus" nectar, meaning more nectar than the bee 
  could carry, it will commence a dance to indicate the direction and distance to the nectar to other bees in the hive, including 
  itself. The direction is indicated by orienting toward the nectar. The directions are confined to the eight compass points. The 
  distance is indicated by displaying a value for short or long distance. Both direction and distance can be sensed by bees in the hive. 
  The graphical view draws a short or long dotted line as a visual representation.</p>
  <p>Once a bee completes the dance, it and any other bees in the hive that sensed the dance will proceed in the direction of 
  the nectar for the distance exhibited by the dance. If any of these bees encounters nectar en route, it will switch over to 
  extracting the nectar and returning with it to the hive, possibly performing a dance there. If no nectar is encountered en 
  route after traveling the indicated distance, the bee resumes phase one foraging.</p>
  <p>If no surplus nectar was sensed after extracting the nectar, the bee will switch to phase one foraging immediately after 
  depositing the nectar.</p>
  <p><b><i>Scenario</b></i></p>
  <p>Figures 5 through 11 present a graphical nectar foraging scenario.</p>
  <img src="images/figure5.png" style="position:relative; left:300px;" />
  <p>Figure 5 - Bee on right is moving down and is about to light on flower.</p>
  <br>
  <img src="images/figure6.png" style="position:relative; left:300px;" />
  <p>Figure 6 - Bee has extracted nectar from flower.</p>
  <br>
  <img src="images/figure7.png" style="position:relative; left:300px;" />
  <p>Figure 7 - Bee with nectar returns directly to the hive to deposit nectar. 
  It is also aware of surplus nectar remaining in the flower. 
  The other bee is incidentally also in the hive.</p>
  <br>
  <img src="images/figure8.png" style="position:relative; left:300px;" />
  <p>Figure 8 - Bee has deposited nectar in the hive. Since the bee knows there is surplus nectar, 
  the bee performs the first part of dance: orient toward nectar.
  If there was no surplus nectar the bee would resume foraging. The other bee is moving about the hive.</p>
  <br>
  <img src="images/figure9.png" style="position:relative; left:300px;" />
  <p>Figure 9 - The second part of dance: indicate a short distance to nectar, as shown by the dotted line. 
  The other bee has become aware of the direction and distance to the nectar.</p>
  <br>
  <img src="images/figure10.png" style="position:relative; left:300px;" />
  <p>Figure 10 - Both bees respond to dance by orienting toward nectar.</p>
  <br>
  <img src="images/figure11.png" style="position:relative; left:300px;" />
  <p>Figure 11 - Both bees move toward nectar.</p>
  <h4 style="font-size: 18px;">Implementation</h4>
  <p><b><i>Modes</b></i></p>
  <p>In <i>autopilot</i> mode, the bees forage programmatically. Autopilot mode generates metamorphs that are used 
  to train the neural network, as shown in Figure 12. Since phase one foraging consists of semi-random movements, 
  metamorphs are only generated in phase two, dealing with known nectar. Once trained, the bees can be switched to 
  <i>metamorphNN</i> mode, in which the neural network drives phase two behavior. Phase one behavior remains programmatic in
  metamorphNN mode. While in metamorphNN mode, new metamorphs are not accumulated.</p>
  <img src="images/figure12.png" style="position:relative; left:190px;" />
  <p style="position:relative; left:50px;">Figure 12 - Generating metamorphs to train the neural network.</p>
  <p><b><i>Morphognostic</b></i></p>
  <p>Each bee contains a morphognostic that maps its sensory inputs as spatial and temporal events that maintain its state in the environment.</p>
  <p style="margin-bottom:0px;"><b>Events</b></p>
  <p style="margin-bottom:0px;">There are 22 binary event variables:</p>
  <ol>
  <li style="margin-bottom:0px;"><i>hive presence</i></li>
  <li style="margin-bottom:0px;"><i>nectar presence</i></li>
  <li style="margin-bottom:0px;"><i>surplus nectar presence</i></li>
  <li style="margin-bottom:0px;"><i>nectar dance direction north</i></li>
  <li style="margin-bottom:0px;"><i>nectar dance direction northeast</i></li>
  <li style="margin-bottom:0px;"><i>nectar dance direction east</i></li>
  <li style="margin-bottom:0px;"><i>nectar dance direction southeast</i></li>
  <li style="margin-bottom:0px;"><i>nectar dance direction south</i></li>
  <li style="margin-bottom:0px;"><i>nectar dance direction southwest</i></li>
  <li style="margin-bottom:0px;"><i>nectar dance direction west</i></li>
  <li style="margin-bottom:0px;"><i>nectar dance direction northwest</i></li>
  <li style="margin-bottom:0px;"><i>nectar dance distance long</i></li>
  <li style="margin-bottom:0px;"><i>nectar dance distance short</i></li>
  <li style="margin-bottom:0px;"><i>orientation north</i></li>
  <li style="margin-bottom:0px;"><i>orientation northeast</i></li>
  <li style="margin-bottom:0px;"><i>orientation east</i></li>
  <li style="margin-bottom:0px;"><i>orientation southeast</i></li>
  <li style="margin-bottom:0px;"><i>orientation south</i></li>
  <li style="margin-bottom:0px;"><i>orientation southwest</i></li>
  <li style="margin-bottom:0px;"><i>orientation west</i></li>
  <li style="margin-bottom:0px;"><i>orientation northwest</i></li>
  <li style="margin-bottom:0px;"><i>nectar carry</i></li>
  </ol>
  <p style="margin-bottom:0px;"><b>Neighborhoods</b></p>
  <p>The morphognostic contains 4 3x3 neighborhoods, with durations and event mappings shown in Table 1.</p>
  <img src="images/table1.png" style="position:relative; left:300px;" />
  <p style="position:relative; left:150px;">Table 1 - Morphognostic neighborhoods.</p>
  <p>Neighborhood 0 maps "immediate" events, such as orientation, that are of use only in the present, as denoted by the duration of 1.</p>
  <p>Neighborhood 1 has a duration, 7, that allows a bee to retain knowledge of the presence of surplus nectar and/or observation of a 
  dance indicating a short distance. The <i>nectar dance short distance</i> event, for example, allows the bee to "count" steps towards surplus nectar.
  When the event expires due to the duration of the neighborhood it no longer affects the bee's behavior.</p>
  <p>Neighborhood 2 serves the same purpose as neighborhood 1, except for <i>nectar dance long distance</i> event, for which the duration,
  and thus steps, is greater than for the <i>nectar dance short distance</i> event.</p>
  <p>Neighborhood 3, as well as all the other neighborhoods, track the presence of the hive as it is recorded in its 3x3 sectors 
  for a long duration of 75. This allows the bee to locate the hive after possibly lengthy foraging and return with nectar. On the 
  rare occasion that 75 steps are taken without returning to the hive, its location will be lost and the bee will be forced to return 
  to the hive without nectar.</p>
  <p>Morphognostic neighborhoods can be configured to either keep a density/average value of event values over its duration, 
  or an on/off event value, meaning the event value is 1 if the event occurs at any time within the neighborhood's duration window. 
  Although surrendering information, the on/off configuration is chosen for the honey bees to improve training time while retaining 
  acceptable performance.</p>
  <p style="margin-bottom:0px;"><b>Example</b></p>
  <p>Figures 13a and 13b show the state of the bee selected by the red square for neighborhood 2 of its morphognostic.</p>
  <img src="images/figure13a.png" style="position:relative; left:350px;" />
  <p style="position:relative; left:30px;">Figure 13a - Bee after dance indicating surplus nectar. The next step is to proceed toward nectar.</p>
  <br>
  <img src="images/figure13b.png" style="position:relative; left:200px;" />
  <p style="position:relative; left:10px;">Figure 13b - Morphognostic neighborhood 2. At the center sector [1, 1] the <i>hive presence</i> and
  <i>nectar dance distance long</i> events are recorded. The location of the surplus nectar is recorded in sector [1, 0] and was used to orient toward the surplus nectar as part of the dance.</p>
  <p><b><i>Code</b></i></p>
  <p>The Java code is available in a GitHub <a href="https://github.com/morphognosis/HoneyBees">repository</a>.</p>
  <h2>Results</h2>
  <h3>Artificial neural network</h3>
  <p>The artificial neural network used was the MultiLayerPerceptron class in the <a href="https://www.cs.waikato.ac.nz/ml/weka">Weka</a> 3.8.3 machine learning library.</p>
  <p>These parameters were used:</p>
  <ul>
  <li style="margin-bottom:0px;">learning rate = 0.1</li>
  <li style="margin-bottom:0px;">momentum = 0.2</li>
  <li style="margin-bottom:0px;">training epochs = 5000</li>
  </ul>
  <p>The morphognostic configured as previously described, four 3x3 neighborhoods, produces 234 binary inputs to the network.
  There are 14 outputs representing the honey bee responses.</p>
  <h3>Base level testing</h3>
  <p>Neither a randomly generated responses nor an untrained network resulted in any nectar collected over 20,000 steps in a 3 
  flower and 3 bee configuration.</p>
  <h3>Test flower and bee quantities</h3>
  <p>In order to determine how the system scales up, three variations of flowers and bees were tested: 3 flowers and bees, 
  5 flowers and bees, and 7 flowers and bees. The amount of nectar collected was used as a success metric.</p>
  <p>The world was set at 21x21 cells, and the hive at radius 3. Flowers were initialized with nectar at random locations outside of the 
  hive. Bees were initialized randomly in the hive. The network was configured with 50 hidden neurons. Running the world for 20,000 
  steps on autopilot generated a metamorph dataset to train the neural network on. Datasets were generated for 10 trials.</p>
  <p>Table 2 shows the average training dataset size and training accuracy. Of note is the increase in the number of metamorphs as 
  the world become more complex with additional flowers.</p>
  <img src="images/table2.png" style="position:relative; left:350px;" />
  <p style="position:relative; left:10px;">Table 2 - Number of metamorphs and training accuracy by varying flower and bee quantities.</p>
  <p>Figure 14 shows the results of running programmatically (Autopilot) vs. with the trained network (Morphognosis).
  The network performs comparably.</p>
  <img src="images/figure14.png" style="position:relative; left:230px;" />
  <p style="position:relative; left:90px;">Figure 14 - Collected nectar for variations of flowers/bees.</p>
  <h3>Test hidden neurons</h3>
  <p>In order to observe how the system is affected by the neural network size, three variation of hidden neuron quantities 
  were tested: 25, 50, and 100.</p>
  <p>Table 3 shows the average training dataset size and training accuracy.</p>
  <img src="images/table3.png" style="position:relative; left:350px;" />
  <p style="position:relative; left:10px;">Table 3 - Number of metamorphs and training accuracy by varying hidden neurons.</p>
  <p>Figure 15 shows the results, indicating that fewer hidden neurons are sufficient to achieve comparable performance.</p>
  <img src="images/figure15.png" style="position:relative; left:230px;" />
  <p style="position:relative; left:80px;">Figure 15 - Collected nectar for variations of hidden neurons.</p>
  <h3>Test hive radius</h3>
  <p>In order to observe how the system is affected by the hive size, two variation of hive sizes were tested: radii of 2 and 3.</p>
  <p>Table 4 shows the average training dataset size and training accuracy. Of note is the reduction in metamorphs with a smaller hive. 
  This is likely due to fewer "trajectories" to and from the hive.</p>
  <img src="images/table4.png" style="position:relative; left:350px;" />
  <p style="position:relative; left:10px;">Table 4 - Number of metamorphs and training accuracy by varying hive radius.</p>
  <p>Figure 16 shows the results, indicating that a smaller hive reduces the amount of nectar collected. 
  A possible contributing factor for this is congestion due to bee collisions.</p>
  <img src="images/figure15.png" style="position:relative; left:230px;" />
  <p style="position:relative; left:90px;">Figure 16 - Collected nectar for variations of hive radius.</p>
  <h3>LSTM performance</h3>
  <p>A key ability of a honey bee is to be able to track the location of the hive as it forages. This allows it to return to 
  the hive with nectar. As a check of the ability of an unaugmented recurrent neural network (RNN) to perform this as a dead 
  reckoning task, a Long Short Term Memory (LSTM) recurrent network <dt-cite key="hochreiter1997"></dt-cite> was trained given sequences
   between 5 and 15 steps consisting of random orientation changes and forward movements probabilistically identical to those used 
   by the honey bees. The output is the direction to the starting position. Despite variations in the network capacity, the 
   training accuracy averaged approximately 30%, which was about the same as a random guess.</p>
  <p>It is important to note a distinction between the training and testing regimens of RNNs, including LSTM, and Morphognosis. 
  RNNs are trained with batches of sequences. Each sequence, possibly having a variable length, has a beginning and end. A test 
  inputs a sequence to the trained network for classification and prediction. Morphognosis, in contrast, having its temporal 
  (and spatial) state embedded in the input, is not bounded by sequences: a honey bee generates a set of training metamorphs as 
  it forages continuously, with no delimiting breaks. This more closely resembles an animal learning situation in nature.</p>
  <p>The LSTM network used is in the <a href="https://github.com/JANNLab/JANNLab">JANN</a> 0.10 machine learning library.</p>
  <h2>Conclusion</h2>
  <p>The brain, a complex structure resulting from millions of years of evolution, can be viewed as a solution to problems posed by an
  environment existing in space and time. Internal spatial and temporal representations allow an organism to navigate and manipulate the
  environment. Following nature's lead, Morphognosis comprises an artificial neural network enhanced with a framework for organizing
  sensory events into hierarchical spatial and temporal contexts.</p>
  <p>The successful simulation of honey bee foraging behavior suggests future projects are worth undertaking:</p>
  <ul>
  <li style="margin-bottom:0px;">The metamorph structure bears a close resemblance to deep reinforcement learning training elements <dt-cite key="francois-lavet2018"></dt-cite>, suggesting the possibility of applying such learning to implement goal-seeking behavior.</li>
  <li style="margin-bottom:0px;">The aggregation scheme that supports scalability is a simple histogram-like method for dimensionality reduction:</li>
    <ul>
    <li style="margin-bottom:0px;">The use of ANN dimensionality reduction techniques, such as autoencoding, might scale with higher information content.</li>
    <li style="margin-bottom:0px;">The value of each neighborhood sector essentially represents a single centroid of sensory event values that have occurred in its space-time cube. An extension of this would be to retain multiple centroids within a sector, possibly weighted by frequency, increasing in number for higher level neighborhoods which encompass greater extents of space-time. This might increase the richness of behavioral variability while limiting information overload.</li>
    </ul>
  <li style="margin-bottom:0px;">The model is currently implemented in a cellular automaton spatial grid of cells. However, it is not inherently tethered to this platform and in fact may benefit from extending beyond it.</li>
  <li style="margin-bottom:0px;">The configuration of the morphognostic is vital to successful performance. For the honey bee task, this was a manual design. This process should be amenable to optimization/evolution methods.</li>
  </ul>
</dt-article>

<dt-appendix>
</dt-appendix>

<script type="text/bibliography">
  @article{bellmund2018,
    title={Navigating cognition: Spatial codes for human thinking},
    author={Bellmund, J. L. S. and G&auml;rdenfors, P. and Moser, E. I. and Doeller, C. F.},
    journal={Science},
    year={2018},
    url={https://science.sciencemag.org/content/362/6415/eaat6766}
  }
  @article{betti2017,
    title={Bee++: An Object-Oriented, Agent-Based Simulator for Honey Bee Colonies},
    author={Betti, M. and LeClair, J. and Wahl, L. M. and Zamir, M.},
    journal={Science},
    year={2017},
    url={https://doi.org/10.3390/insects8010031}
  }
  @article{braitenberg1998,
    title={Statistics and Geometry of Neuronal Connectivity, Second Edition},
    author={Braitenberg, V. and Sch&uuml;z, A.},
    journal={Berlin: Springer-Verlag},
    year={1998}
  }
  @article{bruner2018,
    title={Boundaries Shape Cognitive Representations of Spaces and Events},
    author={Bruner, I. K. and Moscovitch, M. and Barense, M. D.},
    journal={Trends in Cognitive Sciences. Volume 22, Issue 7, P637-650},
    year={2018},
    url={https://doi.org/10.1016/j.tics.2018.03.013}
  }
  @article{chittka2018,
    title={Bee-brained. Are insects 'philosophical zombies' with no inner life? Close attention to their behaviours and moods suggests otherwise.},
    author={Chittka, L. and Wilson, C.},
    journal={Aeon},
    year={2018},
    url={https://aeon.co/essays/inside-the-mind-of-a-bee-is-a-hive-of-sensory-activity}
  }
  @article{collins2019,
    title={The case for emulating insect brains using anatomical "wiring diagrams" equipped with biophysical models of neuronal activity},
    author={Collins, L.},
    journal={Biological Cybernetics},
    year={2019},
    url={https://doi.org/10.1007/s00422-019-00810-z}
  }
  @article{cope2013,
    title={Creating and simulating neural networks in the honeybee brain using a graphical toolchain},
    author={Cope, A. J. and Richmond, P. and Marshall, J. and Allerton, D.},
    year={2013},
    url={http://greenbrain.group.shef.ac.uk/wp-content/uploads/2013/11/SFN_2013_GB.pdf}
  }
  @article{elman1990,
    title={Finding structure in time},
    author={Elman, J. L.},
    journal={Cognitive Science, Volume 14, Issue 2, Pages 179-211},
    year={1990}
  }
  @article{fernando2015,
    title={Modeling a Honeybee using Spiking Neural Network to Simulate Nectar Reporting Behavior},
    author={Fernando, S. and Kumarasinghe, N.},
    journal={International Journal of Computer Applications 130(8):32-39},
    year={2015},
    url={https://doi.org/10.5120/ijca2015907078}
  }
  @article{fox2019,
    title={Bees 'get' addition and subtraction, new study suggests},
    author={Fox, A.},
    journal={Science Magazine},
    year={2019},
    url={https://www.sciencemag.org/news/2019/02/bees-get-addition-and-subtraction-new-study-suggests}
  }
  @article{francois-lavet2018,
    title={An Introduction to Deep Reinforcement Learning},
    author={Francois-Lavet, V. and Henderson, P. and Islam, R. and Bellemare, M. G. and Pineau, J.},
    journal={arxiv},
    year={2018},
    url={https://arxiv.org/abs/1811.12560}
  }
  @article{hainmuller2018,
    title={Parallel emergence of stable and dynamic memory engrams in the hippocampus},
    author={Hainm&uuml;ller, T. and Bartos, M.},
    journal={Nature},
    year={2018},
    url={https://doi.org/10.1038/s41586-018-0191-2}
  }
  @article{hochreiter1997,
    title={Long short-term memory},
    author={Hochreiter, S. and Schmidhuber, J.},
    journal={Neural Computation, 9(8), 1735-1780},
    year={1997}
  }
  @article{karaboga2009,
    title={A survey: algorithms simulating bee swarm intelligence},
    author={Karaboga, D. and Akay, B.},
    journal={Artificial Intelligence Review volume 31, Article number: 61},
    year={2009}
  }
  @article{krakauer2016,
    title={Neuroscience Needs Behavior: Correcting a Reductionist Bias},
    author={Krakauer, J. W. and Ghazanfar, A. A. and Gomez-Marin, A. and Maclver, M. A. and Poeppel, D.},
    journal={Neuron},
    year={2016},
    url={https://doi.org/10.1016/j.neuron.2016.12.041}
  }
  @article{lieff2015,
    title={Time Cells Organize Memory},
    author={Lieff, J.},
    year={2015},
    url={http://jonlieffmd.com/blog/time-cells-organize-memory}
  }
  @article{maboudi2017,
    title={Olfactory learning without the mushroom bodies: Spiking neural network models of the honeybee lateral antennal lobe tract reveal its capacities in odour memory tasks of varied complexities},
    author={MaBouDi, H. and Shimazaki, H. and Giurfa, M. and Chittka, L.},
    journal={PLOS Computational Biology; 13 (6)},
    year={2017},
    url={https://doi.org/10.1371/journal.pcbi.1005551}
  }
  @article{moravec1988,
    title={Mind Children: The Future of Robot and Human Intelligence},
    author={Moravec, H.},
    journal={Harvard University Press},
    year={1988}
  }
  @article{nosowitz2016,
    title={I Asked Leading Entomologists: "What's The Smartest Bug In The World?"},
    author={Nosowitz, D.},
    journal={Atlas Obscura},
    year={2016},
    url={https://getpocket.com/explore/item/i-asked-leading-entomologists-what-s-the-smartest-bug-in-the-world?utm_source=pocket-newtab}
  }
  @article{nott2018,
    title={How a brain the size of a sesame seed could change AI forever},
    author={Nott, G.},
    journal={ComputerWorld},
    year={2018},
    url={https://www.computerworld.com/article/3487862/how-a-brain-the-size-of-a-sesame-seed-could-change-ai-forever.html}
  }
  @article{oldroyd2007,
    title={What's Killing American Honey Bees?},
    author={Oldroyd, B. P.},
    journal={PLoS Biology. 5 (6): e168},
    year={2007},
    url={https://doi.org/10.1371/journal.pbio.0050168}
  }
  @article{portegys1986,
    title={GIL - An Experiment in Goal-Directed Inductive Learning},
    author={Portegys, T. E.},
    journal={Ph.D. dissertation, Northwestern University, Evanston, Illinois, USA},
    year={1986},
    url={https://www.researchgate.net/publication/335568767_GIL_-_an_experiment_in_goal-directed_inductive_learning}
  }
  @article{portegys2007,
    title={Learning Environmental Contexts in a Goal-Seeking Neural Network},
    author={Portegys, T. E.},
    journal={Journal of Intelligent Systems, Vol. 16, No. 2},
    year={2007}
  }
  @article{portegys2010,
    title={A Maze Learning Comparison of Elman, Long Short-Term Memory, and Mona Neural Networks},
    author={Portegys, T. E.},
    journal={Neural Networks},
    year={2010},
    url={https://www.sciencedirect.com/science/article/abs/pii/S0893608009002871?via%3Dihub}
  }
  @article{portegys2013,
    title={Discrimination Learning Guided By Instinct},
    author={Portegys, T. E.},
    journal={Journal of Hybrid Intelligent Systems, 10, 129-136},
    year={2013},
    url={https://doi.org/10.3233/HIS-130171}
  }
  @article{portegys2015,
    title={Training Artificial Neural Networks to Learn a Nondeterministic Game},
    author={Portegys, T. E.},
    journal={ICAI'15: The 2015 International Conference on Artificial Intelligence},
    year={2015},
    url={https://www.researchgate.net/publication/275644397_Training_artificial_neural_networks_to_learn_a_nondeterministic_game}
  }
  @article{portegys2017a,
    title={Morphozoic: cellular automata with nested neighborhoods as a metamorphic representation of morphogenesis},
    author={Portegys, T. and Pascualy, G. and Gordon, R. and McGrew, S. and Alicea, B.},
    journal={In Multi-Agent Based Simulations Applied to Biological and Environmental Systems, ISBN: 978-1-5225-1756-6},
    year={2017},
    url={https://www.igi-global.com/chapter/morphozoic-cellular-automata-with-nested-neighborhoods-as-a-metamorphic-representation-of-morphogenesis/173213}
  }
  @article{portegys2017b,
    title={Morphognosis: the shape of knowledge in space and time},
    author={Portegys, T. E.},
    journal={The 28th Modern Artificial Intelligence and Cognitive Science Conference (MAICS)},
    year={2017},
    url={https://www.researchgate.net/publication/315112721_Morphognosis_the_shape_of_knowledge_in_space_and_time}
  }
  @article{portegys2018,
    title={Learning C. elegans locomotion and foraging with a hierarchical space-time cellular automaton},
    author={Portegys, T. E.},
    journal={Neuroinformatics 2018},
    year={2018},
    url={https://doi.org/10.7490/f1000research.1115884.1}
  }
  @article{portegys2019,
    title={Generating an artificial nest building pufferfish in a cellular automaton through behavior decomposition},
    author={Portegys, T. E.},
    journal={International Journal of Artificial Intelligence and Machine Learning (IJAIML) 9(1)},
    year={2019},
    url={https://doi.org/10.4018/IJAIML.2019010101}
  }
  @article{roper2017,
    title={Insect Bio-inspired Neural Network Provides New Evidence on How Simple Feature Detectors Can Enable Complex Visual Generalization and Stimulus Location Invariance in the Miniature Brain of Honeybees},
    author={Roper, M. and Fernando, C. and Chittka, L.},
    journal={PLoS Comput Biol. Feb; 13(2): e1005333},
    year={2017},
    url={https://doi.org/10.1371/journal.pcbi.1005333}
  }
  @article{schoneburg2019,
    title={Alternative AI (AAI) - An alternative path to AGI},
    author={Sch&ouml;neburg, E.},
    journal={Artificial Life Keynote},
    year={2019},
    url={https://www.youtube.com/watch?v=OeZM1y-AK5U&feature=share&fbclid=IwAR3D_WsLIstB0VaYmPLNzPiuOSE0HVKzXd9GDS3jzHQtFwKIfvRlA8OWozM}
  }
  @article{schurch2019,
    title={Dismantling Babel: creation of a universal calibration for honey bee waggle dance decoding},
    author={Sch&uuml;rch, R. and Zwirner, K. and Yambrick, B. and Pirault, T. and Wilson, J. M. and Couvillon, M. J.},
    journal={Animal Behaviour},
    year={2019},
    url={https://doi.org/10.1016/j.anbehav.2019.01.016}
  }
  @article{tavares2015,
    title={A Map for Social Navigation in the Human Brain},
    author={Tavares, R. M. and Mendelsohn, A. and Grossman, Y. and Williams, C. H. and Shapiro, M. and Trope, Y. and Schiller, D.},
    journal={Neuron. Volume 87, Issue 1, P231-243},
    year={2015},
    url={https://doi.org/10.1016/j.neuron.2015.06.011}
  }
  @article{turing1950,
    title={Computing Machinery and Intelligence},
    author={Turing, A.},
    journal={Mind. LIX (236): 433-460},
    year={1950},
    url={https://en.wikipedia.org/wiki/Turing_test}
  }
  @article{toffoli1987,
    title={Cellular Automata Machines: A New Environment for Modeling},
    author={Toffoli, T. and Margolus, N.},
    journal={MIT Press. p. 27. ISBN 9780262200608},
    year={1987}
  }
  @article{vonfrisch1967,
    title={The Dance Language and Orientation of Bees},
    author={Von Frisch, K.},
    journal={Harvard University Press. ISBN 9780674418776},
    year={1967}
  }
  @article{vorhees2014,
    title={Assessing Spatial Learning and Memory in Rodents},
    author={Vorhees, C. V. and Williams, M. T.},
    journal={ILAR Journal. 55(2), 310-332},
    year={2014},
    url={http://doi.org/10.1093/ilar/ilu013}
  }
  @article{wade2001,
    title={Genome's Riddle: Few Genes, Much Complexity},
    author={Wade, N.},
    journal={The New York Times},
    year={2001},
    url={https://www.nytimes.com/2001/02/13/health/genomes-riddle-few-genes-much-complexity.html}
  }
  @article{wolfram2002,
    title={A New Kind of Science},
    author={Wolfram, S.},
    journal={Wolfram Media. ISBN-10: 1579550088},
    year={2002}
  }
  @article{wood1988,
    title={The Nematode Caenorhabditis elegans},
    author={Wood (editor), W. B.},
    journal={Cold Spring Harbor Monograph Series. ISBN 978-087969433-3},
    year={1988}
  }
  @article{yong2017,
    title={How Brain Scientists Forgot That Brains Have Owners},
    author={Yong, E.},
    journal={The Atlantic},
    year={2017},
    url={https://getpocket.com/explore/item/how-brain-scientists-forgot-that-brains-have-owners?utm_source=pocket-newtab}
  }
  @article{yong2019,
    title={The Human Brain Project Hasn't Lived Up to Its Promise},
    author={Yong, E.},
    journal={The Atlantic},
    year={2019},
    url={https://www.theatlantic.com/science/archive/2019/07/ten-years-human-brain-project-simulation-markram-ted-talk/594493}
  }
  @article{zador2019,
    title={A critique of pure learning and what artificial neural networks can learn from animal brains},
    author={Zador, A.},
    journal={Nature Communications volume 10, Article number: 3770},
    year={2019},
    url={https://www.nature.com/articles/s41467-019-11786-6}
  }
</script>
