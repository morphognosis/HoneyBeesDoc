<!doctype html>
<meta charset="utf-8">
<script src="https://distill.pub/template.v1.js"></script>

<script type="text/front-matter">
  title: "Morphognostic honey bees communicating nectar location through dance movements"
  description:
  authors:
  - Thomas E. Portegys: http://tom.portegys.com/research.html
  affiliations:
  - Dialectek: http://dialectek.com
</script>

<dt-article>
  <h1>Morphognostic honey bees communicating nectar location through dance movements</h1>
  <h2>Honey bees are social insects that forage for flower nectar cooperatively. When an individual
  forager discovers a flower patch rich in nectar, it returns to the hive and performs a "dance" in
  the vicinity of other bees that consists of movements communicating the direction and distance to 
  the nectar source. The bees that receive this information then fly to the location of the nectar to 
  retrieve it, thus cooperatively exploiting the environment. This project simulates this behavior in 
  a cellular automaton using the Morphognosis model. The model features hierarchical spatial and temporal 
  contexts that output motor responses from sensory inputs. Given a set of bee foraging and dancing 
  exemplars, and exposing only the external input-output of these behaviors to the Morphognosis learning 
  algorithm, a hive of artificial bees can be generated that forage as their biological counterparts do.
  <p>
  <h3>Keywords: Honey bee foraging dance, artificial animal intelligence, Morphognosis, cellular automaton, artificial neural network.</h3></h2>
  <dt-byline></dt-byline>
  <h2>Introduction</h2>
  <p>Honey bees, <i>apis mellifera</i>, are fascinating social insects. They are also smart, even able to count and add <dt-cite key="fox2019"></dt-cite>.
  However, it is their ability to communicate symbolically in the form of a "dance" indicating the direction and distance
  to a nectar source that is truly astonishing <dt-cite key="chittka2018"></dt-cite><dt-cite key="nosowitz2016"></dt-cite><dt-cite key="schurch2019"></dt-cite><dt-cite key="vonfrisch1967"></dt-cite>,
  especially considering that the use of symbols is rare even in more neurologically complex animals. The dance, done
  by a bee in the presence of other bees in the hive after discovering nectar at a locale outside the hive, recruits
  bees to forage at the indicated location, thus acquiring more nectar than solitary foraging would otherwise.</p>
  <p>This paper describes artificial honey bees that gather nectar and perform the foraging dance. It employs a general machine 
  learning system, <i>Morphognosis</i>, which acquires behaviors by example and enables an artificial organism to express those behaviors.
  It will be shown that simulating nectar foraging is a difficult task for unaugmented machine learning methods, but with the support 
  of the spatial and temporal contextual information that Morphognosis provides, it can be accomplished.</p>
  <p>As a disclaimer, it should be noted that this project is not intended to offer new or additional findings about honey bees. 
  This is an artificial intelligence project, not a biology study. Its goal is to simulate a biologically inspired behavior in a 
  dynamic environment. It is only functional, "black box" behaviors that are simulated; modeling internal mechanisms is not the aim here.</p>
  <p>Honey bees have been the focus and inspiration for a number of simulation initiatives:</p>
  <ul>
  <li style="margin-bottom:0px;">Detailed colony behavior <dt-cite key="betti2017"></dt-cite>.</li>
  <li style="margin-bottom:0px;">Swarming and group behavior algorithms <dt-cite key="karaboga2009"></dt-cite>.</li>
  <li style="margin-bottom:0px;">Flight neural network <dt-cite key="cope2013"></dt-cite>.</li>
  <li style="margin-bottom:0px;">Visual system neural network <dt-cite key="roper2017"></dt-cite>.</li>
  <li style="margin-bottom:0px;">Odor learning circuits <dt-cite key="maboudi2017"></dt-cite>.</li>
  <li style="margin-bottom:0px;">Spiking neural network that reacts to nectar <dt-cite key="fernando2015"></dt-cite>.</li>
  </ul>
  <p>The colony simulation allows a user to observe how bees are affected by various environmental conditions, such as weather. 
  Algorithms for a number of group behaviors, optimal foraging strategies among them, are cited in the swarming paper.
  The other projects simulate bee-specific neural mechanisms. For example, the odor learning project found that simulated honey 
  bees lacking mushroom bodies, the insect equivalent of the cerebral cortex, may still be able to learn odors. The spiking 
  neural network measures how an abstracted model of a bee's nervous system reacts to nectar-related stimuli.</p>
  <p>In contrast, the contribution of this project is to simulate honey bee behavior with a general purpose connectionist model 
  that learns from external observations and which is applicable to arbitrary behavioral simulation tasks, not just the honey 
  bee foraging task.</p>
  <p>A number of years ago I explained to a coworker how my dissertation program <dt-cite key="portegys1986"></dt-cite>, a model of instrumental/operant
  conditioning, could learn various tasks through reinforcement. He then asked me how "smart" it was. I put him off, not having
  a ready answer. He persisted. So I blurted out that it was as smart as a cockroach (which it is not). To which he replied,
  "Don't we have enough real cockroaches?" Fast forward to this project. Don't we have enough real honey bees? (Maybe we don't <dt-cite key="oldroyd2007"></dt-cite>!)</p>
  <p>The point of this story is that the question of why anyone should work on artificial animal intelligence is, at least on the surface, 
  a reasonable one, given our species unique intellectual accomplishments. Thus, historically, AI has mostly focused on human-like 
  intelligence, for which there are now innumerable success stories: games, self-driving cars, stock market forecasting, medical 
  diagnostics, language translation, image recognition, etc. Yet the elusive goal of artificial general intelligence (AGI) seems as 
  far off as ever. This is because these success stories lack the
  "general" property of AGI, operating as they do within narrow, albeit deep, domains. A language translation application, for 
  example, does just that and nothing else.</p>
  <p>Anthony Zador <dt-cite key="zador2019"></dt-cite> expresses this succinctly: "We cannot build a machine capable of building a nest, or stalking prey, or
  loading a dishwasher. In many ways, AI is far from achieving the intelligence of a dog or a mouse, or even of a spider, and it does 
  not appear that merely scaling up current approaches will achieve these goals."</p>
  <p>I am in the camp that believes that achieving general animal intelligence is a necessary, if not sufficient, path to AGI. While 
  imbuing machines with abstract thought is a worthy goal, in humans there is a massive amount of ancient neurology that underlies 
  this talent.</p>
  <p>Hans Moravec put it thusly <dt-cite key="moravec1988"></dt-cite>: "Encoded in the large, highly evolved sensory and motor portions of the human brain is a billion
  years of experience about the nature of the world and how to survive in it. The deliberate process we call reasoning is, I believe, 
  the thinnest veneer of human thought, effective only because it is supported by this much older and much more powerful, though usually 
  unconscious, sensorimotor knowledge. We are all prodigious Olympians in perceptual and motor areas, so good that we make the difficult 
  look easy. Abstract thought, though, is a new trick, perhaps less than 100 thousand years old. We have not yet mastered it. It is not 
  all that intrinsically difficult; it just seems so when we do it."</p>
  <p>So how should we proceed? Emulating organisms at the level of neurons (whole-brain emulation) is a possible approach to understanding 
  animal intelligence. However, efforts to do this with the human brain have met with little success <dt-cite key="yong2019"></dt-cite>. Scaling down to mice is
  an option. The human brain dwarfs the mouse brain, but even mouse brains are daunting: a cubic milliliter of mouse cortex contains 
  900,000 neurons and 700,000,000 synapses <dt-cite key="braitenberg1998"></dt-cite>. At much a simpler scale, years have been spent studying the 
  relationship between the connectome of the nematode C. elegans <dt-cite key="wood1988"></dt-cite>, with only 302 neurons, and its behaviors, but even this
  creature continues to surprise and elude full definition. Nevertheless, some researchers believe that it is now feasible for the 
  whole-brain approach to be applied to insects such as the fruit fly, with its 135,000 neurons <dt-cite key="collins2019"></dt-cite>. Partial brain analysis
  is also an option. For example, the navigation skills of honey bees are of value to drone technology. Fortunately, it appears that 
  the modular nature of the honey bee brain can be leveraged to replicate this skill <dt-cite key="nott2018"></dt-cite>.</p>
  <p>An issue with emulation, besides the complexity, is the difficulty of mapping the relationship between specific neural structures 
  and behaviors <dt-cite key="krakauer2016"></dt-cite> <dt-cite key="yong2017"></dt-cite>. For AI, this is a key aspect, as behavior is the goal. Artifacts and quirks left
  over by evolution introduce unnecessary complexity in neurological systems. Moreover, even a comprehensive emulation might defy description. 
  Nature, always a blind tinkerer, has been known to work this way. For example, despite the enthusiasm following the mapping of the human 
  genome, the mechanisms by which genes express proteins, and thus phenotypes, is not as modular as hoped for. Rather, it is extraordinarily 
  complex <dt-cite key="wade2001"></dt-cite>.</p>
  <p>The field of artificial life (Alife) offers another path to AGI. This path starts with simulating life, and letting evolution 
  optimize artificial organisms to achieve intelligence as a fitness criteria. Sch&ouml;neburg's <dt-cite key="schoneburg2019"></dt-cite> "alternative path to AGI", sees
  intelligence emerging from <i>holobionts</i>, which form cooperating collectives of artificial agents.</p>
  <p>Another approach, one taken here, is to simulate AI at the behavioral, or functional, level. AI is no more constrained to adhere to 
  biology than aeronautics is confined to bird flight. Considering the vastly different "clay" that biological and computing systems are
  built with, cells vs. transistors and software, behavioral simulation offers another possible path to artificial intelligence.</p>
  <p>Morphognosis comprises an artificial neural network (ANN) enhanced with a framework for organizing sensory events into hierarchical 
  spatial and temporal contexts. Nature has hard-wired knowledge of space and time into the brain as way for it to effectively interact 
  with the environment <dt-cite key="bellmund2018"></dt-cite> <dt-cite key="hainmuller2018"></dt-cite> <dt-cite key="lieff2015"></dt-cite> <dt-cite key="vorhees2014"></dt-cite>. These capabilities
  are modeled by Morphognosis. Interestingly, grid cells also appear in humans to be capable of representing not only spatial relationships,
  but non-spatial multidimensional ones, such as the relationships between members of a group of people <dt-cite key="bruner2018"></dt-cite> <dt-cite key="tavares2015"></dt-cite>.</p>
  <p>The bee dancing behavior, as a sequential process, has temporal components. For example a bee must remember a past event, the existence 
  of surplus nectar in a flower, and use that information to perform a dance that indicates both direction and distance to the nectar. 
  In addition, bees that observe a dance must internally persist the distance signal and use it to measure how far to fly.</p>
  <p>Sequential processes are type of task that recurrent artificial neural networks (RNNs) have been successfully applied 
  to <dt-cite key="elman1990"></dt-cite> <dt-cite key="hochreiter1997"></dt-cite>. However, RNNs do not inherently also support spatial information. RNNs
  maintain internal feedback that allow them to retain state information within the network over time. This contrasts with Morphognosis, 
  where the input itself contains temporal state information.</p>
  <p>Morphognosis was partly inspired by some what-if speculation. In simpler animals, the "old" brain (amygdala, hypothalamus, hippocampus,
  etc.) deals more directly with an unfiltered here-and-now version of the environment. Considering nature's penchant for repurposing
  existing capabilities, might it be that in more complex animals a purpose of the neocortex, sitting atop the old brain and filtering 
  incoming sensory information, is to track events from distant reaches of space and time and render them, as though near and present, to 
  the old brain whose primal functions have changed little over time?</p>
  <p>The author has previously conducted research explorations into a number of issues that differentiate conventional AI from natural 
  intelligence. These include context, motivation, plasticity, modularity, instinct, and surprise <dt-cite key="portegys2007"></dt-cite> <dt-cite key="portegys2010"></dt-cite> <dt-cite key="portegys2013"></dt-cite> <dt-cite key="portegys2015"></dt-cite>. 
  Morphognosis, in particular, has been previously applied to the task of nest-building by a species of pufferfish <dt-cite key="portegys2019"></dt-cite>.</p>
  <p>To date, including the honey bee project, Morphognosis has been implemented as a cellular 
  automaton <dt-cite key="toffoli1987"></dt-cite> <dt-cite key="wolfram2002"></dt-cite>, as the rules that it develops while learning are ideally captured in a grid
  structure. Conceptually, however, Morphognosis is not tied to the cellular automaton scheme.</p>
  <p>The next section describes Morphognosis and details of the behavior and implementation of the honey bees. A section with the results 
  of testing pertinent variables follows. A subsection also presents by way of comparison the performance of a recurrent neural network 
  (see LSTM performance).</p>
  <h2>Description</h2>
  <h2>Results</h2>
  <h2>Conclusion</h2>
  <img src="http://tom.portegys.com/research/morphognosis/waggledance.jpg" width=250 height=250>
</dt-article>

<dt-appendix>
</dt-appendix>

<script type="text/bibliography">
  @article{bellmund2018,
    title={Navigating cognition: Spatial codes for human thinking},
    author={Bellmund, J. L. S. and G&auml;rdenfors, P. and Moser, E. I. and Doeller, C. F.},
    journal={Science},
    year={2018},
    url={https://science.sciencemag.org/content/362/6415/eaat6766}
  }
  @article{betti2017,
    title={Bee++: An Object-Oriented, Agent-Based Simulator for Honey Bee Colonies},
    author={Betti, M. and LeClair, J. and Wahl, L. M. and Zamir, M.},
    journal={Science},
    year={2017},
    url={https://doi.org/10.3390/insects8010031}
  }
  @article{braitenberg1998,
    title={Statistics and Geometry of Neuronal Connectivity, Second Edition},
    author={Braitenberg, V. and Sch&uuml;z, A.},
    journal={Berlin: Springer-Verlag},
    year={1998}
  }
  @article{bruner2018,
    title={Boundaries Shape Cognitive Representations of Spaces and Events},
    author={Bruner, I. K. and Moscovitch, M. and Barense, M. D.},
    journal={Trends in Cognitive Sciences. Volume 22, Issue 7, P637-650},
    year={2018},
    url={https://doi.org/10.1016/j.tics.2018.03.013}
  }
  @article{chittka2018,
    title={Bee-brained. Are insects 'philosophical zombies' with no inner life? Close attention to their behaviours and moods suggests otherwise.},
    author={Chittka, L. and Wilson, C.},
    journal={Aeon},
    year={2018},
    url={https://aeon.co/essays/inside-the-mind-of-a-bee-is-a-hive-of-sensory-activity}
  }
  @article{collins2019,
    title={The case for emulating insect brains using anatomical "wiring diagrams" equipped with biophysical models of neuronal activity},
    author={Collins, L.},
    journal={Biological Cybernetics},
    year={2019},
    url={https://doi.org/10.1007/s00422-019-00810-z}
  }
  @article{cope2013,
    title={Creating and simulating neural networks in the honeybee brain using a graphical toolchain},
    author={Cope, A. J. and Richmond, P. and Marshall, J. and Allerton, D.},
    year={2013},
    url={http://greenbrain.group.shef.ac.uk/wp-content/uploads/2013/11/SFN_2013_GB.pdf}
  }
  @article{elman1990,
    title={Finding structure in time},
    author={Elman, J. L.},
    journal={Cognitive Science, Volume 14, Issue 2, Pages 179-211},
    year={1990}
  }
  @article{fernando2015,
    title={Modeling a Honeybee using Spiking Neural Network to Simulate Nectar Reporting Behavior},
    author={Fernando, S. and Kumarasinghe, N.},
    journal={International Journal of Computer Applications 130(8):32-39},
    year={2015},
    url={https://doi.org/10.5120/ijca2015907078}
  }
  @article{fox2019,
    title={Bees 'get' addition and subtraction, new study suggests},
    author={Fox, A.},
    journal={Science Magazine},
    year={2019},
    url={https://www.sciencemag.org/news/2019/02/bees-get-addition-and-subtraction-new-study-suggests}
  }
  @article{francois-lavet2018,
    title={An Introduction to Deep Reinforcement Learning},
    author={Francois-Lavet, V. and Henderson, P. and Islam, R. and Bellemare, M. G. and Pineau, J.},
    journal={arxiv},
    year={2018},
    url={https://arxiv.org/abs/1811.12560}
  }
  @article{hainmuller2018,
    title={Parallel emergence of stable and dynamic memory engrams in the hippocampus},
    author={Hainm&uuml;ller, T. and Bartos, M.},
    journal={Nature},
    year={2018},
    url={https://doi.org/10.1038/s41586-018-0191-2}
  }
  @article{hochreiter1997,
    title={Long short-term memory},
    author={Hochreiter, S. and Schmidhuber, J.},
    journal={Neural Computation, 9(8), 1735-1780},
    year={1997}
  }
  @article{karaboga2009,
    title={A survey: algorithms simulating bee swarm intelligence},
    author={Karaboga, D. and Akay, B.},
    journal={Artificial Intelligence Review volume 31, Article number: 61},
    year={2009}
  }
  @article{krakauer2016,
    title={Neuroscience Needs Behavior: Correcting a Reductionist Bias},
    author={Krakauer, J. W. and Ghazanfar, A. A. and Gomez-Marin, A. and Maclver, M. A. and Poeppel, D.},
    journal={Neuron},
    year={2016},
    url={https://doi.org/10.1016/j.neuron.2016.12.041}
  }
  @article{lieff2015,
    title={Time Cells Organize Memory},
    author={Lieff, J.},
    year={2015},
    url={http://jonlieffmd.com/blog/time-cells-organize-memory}
  }
  @article{maboudi2017,
    title={Olfactory learning without the mushroom bodies: Spiking neural network models of the honeybee lateral antennal lobe tract reveal its capacities in odour memory tasks of varied complexities},
    author={MaBouDi, H. and Shimazaki, H. and Giurfa, M. and Chittka, L.},
    journal={PLOS Computational Biology; 13 (6)},
    year={2017},
    url={https://doi.org/10.1371/journal.pcbi.1005551}
  }
  @article{moravec1988,
    title={Mind Children: The Future of Robot and Human Intelligence},
    author={Moravec, H.},
    journal={Harvard University Press},
    year={1988}
  }
  @article{nosowitz2016,
    title={I Asked Leading Entomologists: "What's The Smartest Bug In The World?"},
    author={Nosowitz, D.},
    journal={Atlas Obscura},
    year={2016},
    url={https://getpocket.com/explore/item/i-asked-leading-entomologists-what-s-the-smartest-bug-in-the-world?utm_source=pocket-newtab}
  }
  @article{nott2018,
    title={How a brain the size of a sesame seed could change AI forever},
    author={Nott, G.},
    journal={ComputerWorld},
    year={2018},
    url={https://www.computerworld.com/article/3487862/how-a-brain-the-size-of-a-sesame-seed-could-change-ai-forever.html}
  }
  @article{oldroyd2007,
    title={What's Killing American Honey Bees?},
    author={Oldroyd, B. P.},
    journal={PLoS Biology. 5 (6): e168},
    year={2007},
    url={https://doi.org/10.1371/journal.pbio.0050168}
  }
  @article{portegys1986,
    title={GIL - An Experiment in Goal-Directed Inductive Learning},
    author={Portegys, T. E.},
    journal={Ph.D. dissertation, Northwestern University, Evanston, Illinois, USA},
    year={1986},
    url={https://www.researchgate.net/publication/335568767_GIL_-_an_experiment_in_goal-directed_inductive_learning}
  }
  @article{portegys2007,
    title={Learning Environmental Contexts in a Goal-Seeking Neural Network},
    author={Portegys, T. E.},
    journal={Journal of Intelligent Systems, Vol. 16, No. 2},
    year={2007}
  }
  @article{portegys2010,
    title={A Maze Learning Comparison of Elman, Long Short-Term Memory, and Mona Neural Networks},
    author={Portegys, T. E.},
    journal={Neural Networks},
    year={2010},
    url={https://www.sciencedirect.com/science/article/abs/pii/S0893608009002871?via%3Dihub}
  }
  @article{portegys2013,
    title={Discrimination Learning Guided By Instinct},
    author={Portegys, T. E.},
    journal={Journal of Hybrid Intelligent Systems, 10, 129-136},
    year={2013},
    url={https://doi.org/10.3233/HIS-130171}
  }
  @article{portegys2015,
    title={Training Artificial Neural Networks to Learn a Nondeterministic Game},
    author={Portegys, T. E.},
    journal={ICAI'15: The 2015 International Conference on Artificial Intelligence},
    year={2015},
    url={https://www.researchgate.net/publication/275644397_Training_artificial_neural_networks_to_learn_a_nondeterministic_game}
  }
  @article{portegys2017a,
    title={Morphozoic: cellular automata with nested neighborhoods as a metamorphic representation of morphogenesis},
    author={Portegys, T. and Pascualy, G. and Gordon, R. and McGrew, S. and Alicea, B.},
    journal={In Multi-Agent Based Simulations Applied to Biological and Environmental Systems, ISBN: 978-1-5225-1756-6},
    year={2017},
    url={https://www.igi-global.com/chapter/morphozoic-cellular-automata-with-nested-neighborhoods-as-a-metamorphic-representation-of-morphogenesis/173213}
  }
  @article{portegys2017b,
    title={Morphognosis: the shape of knowledge in space and time},
    author={Portegys, T. E.},
    journal={The 28th Modern Artificial Intelligence and Cognitive Science Conference (MAICS)},
    year={2017},
    url={https://www.researchgate.net/publication/315112721_Morphognosis_the_shape_of_knowledge_in_space_and_time}
  }
  @article{portegys2018,
    title={Learning C. elegans locomotion and foraging with a hierarchical space-time cellular automaton},
    author={Portegys, T. E.},
    journal={Neuroinformatics 2018},
    year={2018},
    url={https://doi.org/10.7490/f1000research.1115884.1}
  }
  @article{portegys2019,
    title={Generating an artificial nest building pufferfish in a cellular automaton through behavior decomposition},
    author={Portegys, T. E.},
    journal={International Journal of Artificial Intelligence and Machine Learning (IJAIML) 9(1)},
    year={2019},
    url={https://doi.org/10.4018/IJAIML.2019010101}
  }
  @article{roper2017,
    title={Insect Bio-inspired Neural Network Provides New Evidence on How Simple Feature Detectors Can Enable Complex Visual Generalization and Stimulus Location Invariance in the Miniature Brain of Honeybees},
    author={Roper, M. and Fernando, C. and Chittka, L.},
    journal={PLoS Comput Biol. Feb; 13(2): e1005333},
    year={2017},
    url={https://doi.org/10.1371/journal.pcbi.1005333}
  }
  @article{schoneburg2019,
    title={Alternative AI (AAI) - An alternative path to AGI},
    author={Sch&ouml;neburg, E.},
    journal={Artificial Life Keynote},
    year={2019},
    url={https://www.youtube.com/watch?v=OeZM1y-AK5U&feature=share&fbclid=IwAR3D_WsLIstB0VaYmPLNzPiuOSE0HVKzXd9GDS3jzHQtFwKIfvRlA8OWozM}
  }
  @article{schurch2019,
    title={Dismantling Babel: creation of a universal calibration for honey bee waggle dance decoding},
    author={Sch&uuml;rch, R. and Zwirner, K. and Yambrick, B. and Pirault, T. and Wilson, J. M. and Couvillon, M. J.},
    journal={Animal Behaviour},
    year={2019},
    url={https://doi.org/10.1016/j.anbehav.2019.01.016}
  }
  @article{tavares2015,
    title={A Map for Social Navigation in the Human Brain},
    author={Tavares, R. M. and Mendelsohn, A. and Grossman, Y. and Williams, C. H. and Shapiro, M. and Trope, Y. and Schiller, D.},
    journal={Neuron. Volume 87, Issue 1, P231-243},
    year={2015},
    url={https://doi.org/10.1016/j.neuron.2015.06.011}
  }
  @article{toffoli1987,
    title={Cellular Automata Machines: A New Environment for Modeling},
    author={Toffoli, T. and Margolus, N.},
    journal={MIT Press. p. 27. ISBN 9780262200608},
    year={1987}
  }
  @article{vonfrisch1967,
    title={The Dance Language and Orientation of Bees},
    author={Von Frisch, K.},
    journal={Harvard University Press. ISBN 9780674418776},
    year={1967}
  }
  @article{vorhees2014,
    title={Assessing Spatial Learning and Memory in Rodents},
    author={Vorhees, C. V. and Williams, M. T.},
    journal={ILAR Journal. 55(2), 310-332},
    year={2014},
    url={http://doi.org/10.1093/ilar/ilu013}
  }
  @article{wade2001,
    title={Genome's Riddle: Few Genes, Much Complexity},
    author={Wade, N.},
    journal={The New York Times},
    year={2001},
    url={https://www.nytimes.com/2001/02/13/health/genomes-riddle-few-genes-much-complexity.html}
  }
  @article{wolfram2002,
    title={A New Kind of Science},
    author={Wolfram, S.},
    journal={Wolfram Media. ISBN-10: 1579550088},
    year={2002}
  }
  @article{wood1988,
    title={The Nematode Caenorhabditis elegans},
    author={Wood (editor), W. B.},
    journal={Cold Spring Harbor Monograph Series. ISBN 978-087969433-3},
    year={1988}
  }
  @article{yong2017,
    title={How Brain Scientists Forgot That Brains Have Owners},
    author={Yong, E.},
    journal={The Atlantic},
    year={2017},
    url={https://getpocket.com/explore/item/how-brain-scientists-forgot-that-brains-have-owners?utm_source=pocket-newtab}
  }
  @article{yong2019,
    title={The Human Brain Project Hasn't Lived Up to Its Promise},
    author={Yong, E.},
    journal={The Atlantic},
    year={2019},
    url={https://www.theatlantic.com/science/archive/2019/07/ten-years-human-brain-project-simulation-markram-ted-talk/594493}
  }
  @article{zador2019,
    title={A critique of pure learning and what artificial neural networks can learn from animal brains},
    author={Zador, A.},
    journal={Nature Communications volume 10, Article number: 3770},
    year={2019},
    url={https://www.nature.com/articles/s41467-019-11786-6}
  }
</script>
